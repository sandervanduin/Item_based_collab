{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-Based Collaborative Filtering Movielens\n",
    "\n",
    "This notebook explores the concept of Item-Based Collaborative Filtering, an increasingly popular recommendation algorithm. Large enterprises, recognizing the benefits of personalized recommendations, are increasingly investing in research and implementation of recommender systems. How it works?? The algorithm works by finding the similarity between items based on the ratings users have given them. The assumption here is that if two items are similar, a user who liked one item would also likely enjoy the other.\n",
    "\n",
    "`This notebook is made by Sander van Duin`\n",
    "\n",
    "This notebook will also guide you through all the coding work that is needed to build (basic) recommender systems. The aim of this notebook is to investigate the application of collaborative filtering techniques for Movielens.      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">0. Importing Packages</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyarrow import parquet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.sparse import issparse\n",
    "from fuzzywuzzy import process\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import vstack\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Package                                      | Description                                                                                       | Benefit                                                                                                   |\n",
    "|----------------------------------------------|---------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| **pandas**                                   | A library providing high-performance, easy-to-use data structures, and data analysis tools.       | Facilitates data manipulation and analysis, making data exploration and cleaning efficient.               |\n",
    "| **numpy**                                    | A fundamental package for scientific computing with Python, supporting large, multi-dimensional arrays and matrices. | Offers comprehensive mathematical functions, enabling complex numerical operations with ease.             |\n",
    "| **pyarrow.parquet**                          | A part of PyArrow for reading and writing the Parquet format, efficiently storing tabular data in columnar format. | Enables high-performance data storage and retrieval, supporting efficient compression and encoding schemes. |\n",
    "| **matplotlib**                               | A plotting library for creating static, interactive, and animated visualizations in Python.      | Provides a versatile way to visualize data, with extensive support for custom plots and graphs.           |\n",
    "| **sklearn.model_selection.train_test_split** | A function for splitting dataset arrays into random train and test subsets.                       | Essential for evaluating the performance of a model by training on one subset and testing on another.      |\n",
    "| **scipy.sparse.csr_matrix**                  | A SciPy class for a sparse matrix in Compressed Sparse Row format.                                | Saves memory and improves performance for operations on sparse matrices, which have a lot of zeros.       |\n",
    "| **sklearn.metrics.mean_squared_error**       | A metric to measure the average of the squares of the errors or deviations.                       | Useful for assessing the accuracy of a regression model, penalizing larger errors more than smaller ones. |\n",
    "| **sklearn.metrics.mean_absolute_error**      | A metric to measure the mean absolute difference between predicted and actual values.             | Provides a straightforward way to understand the average error magnitude a model may have.                |\n",
    "| **scipy.sparse.issparse**                    | A function to check whether a matrix is a sparse matrix.                                          | Allows for conditional operations based on the storage scheme of the matrix, optimizing performance.      |\n",
    "| **fuzzywuzzy.process**                       | A part of FuzzyWuzzy, a library for string matching, allowing for approximate matches.            | Helps in matching similar strings, useful in tasks like data cleaning and validation where exact matches are not possible. |\n",
    "| **sklearn.neighbors.NearestNeighbors**       | A class for unsupervised learner for implementing neighbor searches.                               | Facilitates finding the nearest neighbors of a point, useful in algorithms like k-nearest neighbors for both classification and regression. |\n",
    "| **scipy.sparse vstack**                      | Vertical stacking (vstack) if the matrices have the same number of columns but different numbers of rows.                         | Instead of using the + operator, which requires matrices of the same shape, you can use vertical stacking if the matrices have the same number of columns but different numbers of rows         \n",
    "| Collections Counter                          | This module is used to count the occurrences of elements within an iterable object. It returns a dictionary-like object where elements of the iterable are the keys, and their corresponding counts are the values. | Efficient Counting, Automatic zero count, and useful to analyze the occurences within elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">1. Preparing the Dataset</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `loading_datasets`\n",
    "\n",
    "This function is designed to load a movie dataset from a specified path, focusing on a file in the Parquet format. The steps followed in this function are outlined below:\n",
    "\n",
    "#### 1. **Specify the File Path:**\n",
    "- The function accepts a base path as input, which is expected to be the directory where the dataset is stored. The filename `'movielens_item_pers1.parquet'` is appended to this base path to form the full path to the dataset.\n",
    "#### 2. **Read the Dataset:**\n",
    "- Pandas is used to read the Parquet file using the `pyarrow` engine. This method efficiently loads the dataset into a DataFrame `df`, accommodating large datasets.\n",
    "#### 3. **Dataset Dimensions & Unique Elements Analysis:**\n",
    "- The function prints the dimensions of the loaded DataFrame to provide an immediate understanding of its scale, displaying the total number of rows and columns.\n",
    "- It calculates and prints the count of unique movies (`itemid`), users (`userid`), and ratings (`rating`) found within the dataset.\n",
    "- Additionally, it computes the number of unique genres (or genre combinations) available in the dataset, which are going to needed later on\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the movies dataset are: (24988355, 6)\n",
      "The number of unique movies in the movies dataset is 58675\n",
      "The number of unique users in the movies dataset is 162541\n",
      "The number of unique ratings in the movies dataset is 10\n",
      "The number of unique genres (genre combinations) in the movies dataset is 1621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  itemid  rating                title                        genre  \\\n",
       "0       1     296     5.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "1       3     296     5.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "2       4     296     4.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "3       5     296     4.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "4       7     296     4.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "\n",
       "   year  \n",
       "0  1994  \n",
       "1  1994  \n",
       "2  1994  \n",
       "3  1994  \n",
       "4  1994  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loading_datasets(base_path):\n",
    "    # Load the dataset\n",
    "    parquet_file = base_path + 'movielens_item_pers1.parquet'\n",
    "    # 'pyarrow' is a fast and efficient library for reading and writing data in Parquet format.\n",
    "    df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "    print('The dimensions of the movies dataset are:', df.shape)\n",
    "\n",
    "    # Check the number of unique items and users\n",
    "    unique_items = df['itemid'].nunique()\n",
    "    unique_users = df['userid'].nunique()\n",
    "    unique_ratings = df['rating'].nunique()\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"The number of unique movies in the movies dataset is {unique_items}\")\n",
    "    print(f\"The number of unique users in the movies dataset is {unique_users}\")\n",
    "    print(f\"The number of unique ratings in the movies dataset is {unique_ratings}\")\n",
    "    print(f\"The number of unique genres (genre combinations) in the movies dataset is {df['genre'].nunique()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "base_path = '/Users/sandervanduin/Desktop/CSV_parquet/'\n",
    "df = loading_datasets(base_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Data Filtering\n",
    "### & Sampling (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `data_filtering` function refines the dataset by removing infrequent users and movies with few ratings. This ensures that subsequent analysis is based on reliable and significant interaction data, improving the quality of insights and recommendations.\n",
    "\n",
    "#### Function Overview\n",
    "\n",
    "The function filters the dataset in two key steps:\n",
    "\n",
    "1. **User Activity Filter**: It excludes users who have rated a lower percentage of movies than the specified threshold. This focuses the dataset on active users.\n",
    "2. **Movie Popularity Filter**: It removes movies that have not received a minimum number of ratings, concentrating on well-reviewed movies.\n",
    "\n",
    "#### Parameters\n",
    "- `mimimum_percentage_movies_user_rated`: The minimum percentage of movies a user must have rated to be included in the dataset.\n",
    "- `minimum_ratings_per_movie`: The minimum number of ratings a movie must have to remain in the dataset.\n",
    "\n",
    "#### Sample\n",
    "- `Sample`: If you want to experiment with a small sample, switch to `TRUE`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing users who have rated less than 2.0% of all movies\n",
      "Filtered dataset size after removing less active users: 3245471\n",
      "\n",
      "Removing movies that have been rated by fewer than 50 users\n",
      "Filtered dataset size after removing less rated movies: 3045632\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>187</td>\n",
       "      <td>296</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>548</td>\n",
       "      <td>296</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>757</td>\n",
       "      <td>296</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>803</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>847</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid  itemid  rating                title                        genre  \\\n",
       "90      187     296     4.5  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "261     548     296     4.5  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "362     757     296     3.5  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "382     803     296     5.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "405     847     296     4.0  Pulp Fiction (1994)  Comedy|Crime|Drama|Thriller   \n",
       "\n",
       "     year  \n",
       "90   1994  \n",
       "261  1994  \n",
       "362  1994  \n",
       "382  1994  \n",
       "405  1994  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the sampled dataset are: (3045632, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def data_filtering(df, mimimum_percentage_movies_user_rated=0.02, minimum_ratings_per_movie=50):\n",
    "\n",
    "    # Count the number of ratings for each movie and each user\n",
    "    ratings_per_movie = df.groupby('itemid').size().reset_index(name='ratings_per_movie')\n",
    "    ratings_per_user = df.groupby('userid').size().reset_index(name='number_rated')\n",
    "    # Filter out users who have rated less than the minimum percentage of movies\n",
    "    eligible_users = ratings_per_user[ratings_per_user['number_rated'] / ratings_per_movie.shape[0] > mimimum_percentage_movies_user_rated]\n",
    "    df_filtered_users = df[df['userid'].isin(eligible_users['userid'])]\n",
    "    # Filter out movies that have been rated by less than the threshold number of users\n",
    "    eligible_movies = ratings_per_movie[ratings_per_movie['ratings_per_movie'] >= minimum_ratings_per_movie]\n",
    "    df_filtered = df_filtered_users[df_filtered_users['itemid'].isin(eligible_movies['itemid'])]\n",
    "    # Print the results\n",
    "    print(f'Removing users who have rated less than {mimimum_percentage_movies_user_rated*100}% of all movies')\n",
    "    print(f'Filtered dataset size after removing less active users: {df_filtered_users.shape[0]}\\n')\n",
    "    print(f'Removing movies that have been rated by fewer than {minimum_ratings_per_movie} users')\n",
    "    print(f'Filtered dataset size after removing less rated movies: {df_filtered.shape[0]}\\n')\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# You can now call the filter_data function with sample_df as an argument.\n",
    "df_filtered = data_filtering(df, mimimum_percentage_movies_user_rated=0.02, minimum_ratings_per_movie=50)\n",
    "\n",
    "########################\n",
    "\n",
    "# For experimenting with a smaller dataset, you can sample a fraction of the filtered dataset\n",
    "# This will reduce the time it takes to run the codes\n",
    "\n",
    "sampling = False\n",
    "\n",
    "if sampling == True:\n",
    "    df_filtered = df_filtered.sample(frac=0.1, random_state=42)\n",
    "\n",
    "display((df_filtered.head(5)))\n",
    "print('The dimensions of the sampled dataset are:', df_filtered.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Creating an Item-User Matrix\n",
    "###  & Creating Dictionaries and Mappings for Movie Title and Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section outlines the process of preparing the dataset for an item-based collaborative filtering approach. The process involves calculating the unique users and items, establishing mappings between user and item IDs to matrix indices, and creating a sparse matrix representing the item-user interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation for Collaborative Filtering\n",
    "\n",
    "**Step 1: Identify Unique Users and Items**\n",
    "First, we calculate the unique users and items in the dataset to understand the dimensions of our user-item interaction matrix.\n",
    "```python\n",
    "num_users = sorted(...\n",
    "num_items = sorted(...\n",
    "```\n",
    "This step is important for the next phase, where we will map these IDs to specific indices in our matrix.\n",
    "\n",
    "**Step 2: Create ID-to-Index Mappings**\n",
    "To facilitate matrix operations, we map user and item IDs to specific indices. This mapping simplifies accessing and updating the matrix based on user/item interactions.\n",
    "```python\n",
    "user_to_index = {user_id: ...\n",
    "item_to_index = {item_id: ...\n",
    "```\n",
    "These mappings are important for translating between the dataset's IDs and the indices in the computational models.\n",
    "\n",
    "**Step 3: Auxiliary Dictionaries for Titles and Genres**\n",
    "For enhancing the interpretability of our recommendations, we create dictionaries to map movie IDs to their titles and genres.\n",
    "```python\n",
    "movie_title_dict = {movie_id: title ...\n",
    "movie_genre_dict = {movie_id: genre ...\n",
    "```\n",
    "This allows us to provide more meaningful recommendations by using movie titles and genres instead of abstract IDs.\n",
    "\n",
    "**Step 4: Construct the Item-User Matrix**\n",
    "Finally, we construct a sparse matrix representing the item-user interactions. Each row corresponds to an item, each column to a user, and the cell values represent the rating given by a user to an item.\n",
    "```python\n",
    "item_user_matrix = csr_matrix(df_filtered.pivot_table(index='itemid', columns='userid', values='rating').fillna(0).values)\n",
    "```\n",
    "\n",
    "**Step 5: Validation**\n",
    "- The validationis to check if the mapping is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not using a manually constructed Matrix\n",
    "- ---> Therefore choosing csr_matrix, imported from scipy.sparse\n",
    "\n",
    "Due to  memory use and computational efficiency, I decided to not manually construct a sparse matrix. Manually populating a matrix significantly increases memory overhead and processing time, particularly with large datasets.\n",
    "\n",
    "The approach of using csr_matrix, imported from scipy.sparse it increases memory efficiency by storing only the non-zero elements, and that is especially useful for very large matrices with many zeros like this dataset of Movielens. Moreover, the csr_matrix is able to make fast matrix-vextor multiplications due to the efficient representation of the sparse structure. Additionally, the CSR format significantly enhances the scalability of data processing and Hyperparameter Tuning on the Movielens dataset, enabling the handling of larger datasets and more complex models without compromising performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the item-user matrix:\n",
      "  (0, 0)\t3.5\n",
      "  (0, 1)\t4.5\n",
      "  (0, 2)\t4.5\n",
      "  (0, 3)\t3.0\n",
      "  (0, 4)\t5.0\n",
      "  (1, 0)\t3.5\n",
      "  (1, 1)\t4.0\n",
      "  (1, 2)\t4.0\n",
      "  (1, 3)\t3.0\n",
      "  (2, 0)\t3.0\n",
      "\n",
      "Validation example to check if the mapping is correct\n",
      "Sample movie ID: 50794\n",
      "Matrix index: 8515\n",
      "Title: Smokin' Aces (2006)\n",
      "Genre: Action|Crime|Drama|Thriller\n",
      "\n",
      "All movies covered in dictionaries: True\n",
      "All genres covered in dictionaries: True\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of unique users and items accurately\n",
    "num_users = sorted(df_filtered['userid'].unique())  # Calculate the number of unique users in the sampled interactions\n",
    "num_items = sorted(df_filtered['itemid'].unique())  # Calculate the number of unique items (movies) in the sampled interactions\n",
    "\n",
    "# Establish mappings from IDs to matrix indices\n",
    "user_to_index = {user_id: index for index, user_id in enumerate(num_users)} # Create a mapping from user IDs to matrix indices\n",
    "item_to_index = {item_id: index for index, item_id in enumerate(num_items)} # Create a mapping from item IDs to matrix indices\n",
    "index_to_item = {index: item_id for item_id, index in item_to_index.items()}\n",
    "index_to_user = {index: user_id for user_id, index in user_to_index.items()}\n",
    "\n",
    "# Create dictionaries for mapping between indices and titles and genres\n",
    "movie_title_dict = {movie_id: title for movie_id, title in zip(df_filtered['itemid'], df_filtered['title'])}\n",
    "movie_genre_dict = {movie_id: genre for movie_id, genre in zip(df_filtered['itemid'], df_filtered['genre'])}\n",
    "\n",
    "# Initialise lists to store row, column, and data for the sparse matrix\n",
    "rows = []  \n",
    "cols = []  \n",
    "data = []  \n",
    "\n",
    "# Populate the lists with data\n",
    "for index, row in df_filtered.iterrows():\n",
    "    user_index = user_to_index[row['userid']]  # Map the user ID to its corresponding index in the matrix (columns)\n",
    "    item_index = item_to_index[row['itemid']]  # Map the item ID to its corresponding index in the matrix (rows)\n",
    "    rating = row['rating']  # Get the rating value\n",
    "    \n",
    "    # Append the item index, user index, and rating to their respective lists\n",
    "    rows.append(item_index)\n",
    "    cols.append(user_index)\n",
    "    data.append(rating)\n",
    "\n",
    "# *** The self made matrix is not going to be used due to the lack of memory and computational time ***\n",
    "\n",
    "# **** Therefore, the sparse matrix is going to be used ****\n",
    "item_user_matrix = csr_matrix(df_filtered.pivot_table(index='itemid', columns='userid', values='rating').fillna(0).values)\n",
    "# print first rows of the matrix\n",
    "print(\"First 5 rows of the item-user matrix:\")\n",
    "print(item_user_matrix[:5, :5])\n",
    "\n",
    "\n",
    "######## Validation checks ########\n",
    "\n",
    "# The validation has been done because of checking if the mapping is correct\n",
    "\n",
    "# Validation example to check if the mapping is correct\n",
    "filtered_movie_id = df_filtered['itemid'].sample(1).iloc[0]\n",
    "matrix_index = item_to_index[filtered_movie_id]\n",
    "title = movie_title_dict[filtered_movie_id]\n",
    "genre = movie_genre_dict[filtered_movie_id]\n",
    "\n",
    "print(\"\\nValidation example to check if the mapping is correct\")\n",
    "print(f\"Sample movie ID: {filtered_movie_id}\")\n",
    "print(f\"Matrix index: {matrix_index}\")\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Genre: {genre}\")\n",
    "\n",
    "all_movies_covered = all(movieId in movie_title_dict and movieId in movie_genre_dict for movieId in item_to_index.keys())\n",
    "all_genres_covered = all(genre in movie_genre_dict.values() for genre in movie_genre_dict.values())\n",
    "print(f\"\\nAll movies covered in dictionaries: {all_movies_covered}\")\n",
    "print(f\"All genres covered in dictionaries: {all_genres_covered}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Train, Test, Splitting Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This code is used to display the train, test, and validation sets in a histogram format\n",
    "- --> This code will not be used in hyperparameter tuning. A seperate train, test, split will be used there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The package train_test_split\n",
    "\n",
    "The `train_test_split` function, part of the `sklearn.model_selection` package, is instrumental in dividing a dataset into two distinct parts: a training set for developing a machine learning model, and a testing set for evaluating its efficacy. This division is carried out randomly according to a predefined ratio, ensuring that both sets are representative of the overall dataset.\n",
    "\n",
    "`Functionality`:\n",
    "\n",
    "- It splits the dataset into subsets for both training and evaluation purposes.\n",
    "- The division ratio between the training and testing datasets can be customized as needed.\n",
    "- Prior to division, the dataset undergoes a random shuffle to guarantee that the split is unbiased and incorporates randomness.\n",
    "- The output consists of four arrays: the training input, test input, and training and test lables\n",
    "\n",
    "`Advantages`:\n",
    "\n",
    "- It enables effective model validation: By allocating a portion of the data exclusively for testing, it is possible to gauge the modelâ€™s performance on data it has not seeb, assessing its predictive power.\n",
    "- It aids in identifying overfitting: Using a separate test dataset helps uncover instances where the model might memorize the training data rather than learning general patterns, thus ensuring the model's utility with new data.\n",
    "- It supports fine-tuning of hyperparameters: By setting aside a test dataset, the function allows for the experimentation with various model settings to determine the optimal configuration, enhancing model performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9210, 1803)\n",
      "(1974, 1803)\n",
      "(1974, 1803)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the sparse matrix into 70% train and 30% temporary data (which will be further split into validation and test)\n",
    "train_data_plot, temp_data = train_test_split(item_user_matrix, test_size=0.30, random_state=42)\n",
    "# Split the temporary data equally into validation and test sets (50% each, amounting to 15% of the original data each)\n",
    "val_data_plot, test_data_plot = train_test_split(temp_data, test_size=0.50, random_state=42)\n",
    "\n",
    "# Print the shapes of the training, testing, and validation sets\n",
    "print(train_data_plot.shape)\n",
    "print(test_data_plot.shape)\n",
    "print(val_data_plot.shape)\n",
    "\n",
    "# Function to plot histograms\n",
    "def plot_distribution(data, title):\n",
    "    plt.hist(data, bins=30, alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Ratings')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "# Count the number of non-zero ratings for each movie\n",
    "train_ratings_per_movie = train_data_plot.getnnz(axis=1)\n",
    "test_ratings_per_movie = test_data_plot.getnnz(axis=1)\n",
    "val_ratings_per_movie = val_data_plot.getnnz(axis=1)\n",
    "\n",
    "# Plot histograms for number of ratings per movie for train, test, and validation sets\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plot_distribution(train_ratings_per_movie, 'Train Set: Ratings per Movie')\n",
    "plt.subplot(1, 3, 2)\n",
    "plot_distribution(test_ratings_per_movie, 'Test Set: Ratings per Movie')\n",
    "plt.subplot(1, 3, 3)\n",
    "plot_distribution(val_ratings_per_movie, 'Validation Set: Ratings per Movie')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">2. Item Based Prediction Models</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter will focus on building the item (movie) recommendation models\n",
    "- There is one model who only predicts ratings based on the weighted sum of ratings from top-K similar movies, based on similarity scores\n",
    "- There are two recommendation model which also predict ratings\n",
    "\n",
    "This chapter will explore item-based collaborative filtering as a method for recommending movies by leveraging the similarities between items (movies) themselves, rather than user-user comparisons. It seeks to demonstrate how this approach can provide personalized movie recommendations by predicting user ratings with a focus on the underlying patterns within the movie dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Simple predicted rating per selected movie for a specific user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this simple prediction model I used the cosine_similarity package to quickly calculate similarities between items. In the recommender models I will not use this package. \n",
    "- `from sklearn.metrics.pairwise import cosine_similarity` ---> The cosine_similarity function computes the cosine similarity between samples in one or two arrays, measuring the cosine of the angle between vectors in a multidimensional space. This metric, ranging from -1 to 1, is widely used in machine learning to assess how similar two items are based on their features, with 1 indicating identical directionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`predict_rating Function`\n",
    "- **Purpose:** Predicts ratings for a randomly selected movie and user by leveraging item similarities. It embodies the essence of collaborative filtering by considering how similar users rated the movie to infer a targeted prediction.\n",
    "Process:\n",
    "- **Random Selection**: Chooses a movie and a user at random to simulate a prediction scenario.\n",
    "- **Similarity Retrieval**: Extracts cosine similarities for the selected movie against all others in the dataset.\n",
    "- **Top-K Similarity Selection**: Identifies the top-K similar movies to the selected one, ensuring the prediction is based on the most relevant comparisons.\n",
    "- **Rating Prediction**: Calculates the predicted rating using a weighted sum of ratings from the top-K similar movies, adjusted by their similarity scores. This method intuitively captures the premise that more similar movies should have a greater influence on the prediction.\n",
    "- **Fallback Strategy**: Implements a fallback mechanism to use the average rating of the selected movie if it's unrated by the user. This pragmatic approach ensures a prediction is always provided, enhancing user experience by avoiding null responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Movie Index: 9012\n",
      "Selected Movie ID: 59103\n",
      "Selected Movie Title: Forbidden Kingdom, The (2008)\n",
      "User Index: 1164\n",
      "\n",
      "Predicted rating for movie 9012 by user 1164: 3.06\n"
     ]
    }
   ],
   "source": [
    "def calculate_similarity (item_user_matrix):\n",
    "    # Compute the cosine similarity between all items\n",
    "    item_similarity = cosine_similarity(item_user_matrix, dense_output=False)\n",
    "    return item_similarity\n",
    "\n",
    "def predict_rating(item_user_matrix, item_to_index, movie_title_dict, k=10):\n",
    "    # Compute the cosine similarity between all items\n",
    "    item_similarity = cosine_similarity(item_user_matrix, dense_output=False)\n",
    "\n",
    "    # Select a movie and user for prediction\n",
    "    selected_movie_index = np.random.choice(item_user_matrix.shape[0])\n",
    "    user_index = np.random.choice(item_user_matrix.shape[1])\n",
    "\n",
    "    # Reverse-map selected movie index to movie ID\n",
    "    selected_movie_id = index_to_item[selected_movie_index]\n",
    "\n",
    "    # Look up the movie title\n",
    "    selected_movie_title = movie_title_dict.get(selected_movie_id, \"Unknown Title\")\n",
    "\n",
    "    print(f\"Selected Movie Index: {selected_movie_index}\")\n",
    "    print(f\"Selected Movie ID: {selected_movie_id}\")\n",
    "    print(f\"Selected Movie Title: {selected_movie_title}\")\n",
    "    print(f\"User Index: {user_index}\")\n",
    "\n",
    "    # Get the similarities for the selected movie\n",
    "    similarities = item_similarity[selected_movie_index]\n",
    "\n",
    "    # Sort movies by similarity and select the top k\n",
    "    top_k_indices = np.argsort(similarities)[-k:]\n",
    "\n",
    "    # Initialize variables for weighted sum and similarity sum\n",
    "    weighted_sum = 0\n",
    "    similarity_sum = 0\n",
    "\n",
    "    for index in top_k_indices:\n",
    "        user_rating = item_user_matrix[index, user_index]\n",
    "        # Skip movies that the user has not rated\n",
    "        if user_rating > 0:\n",
    "            weighted_sum += similarities[index] * user_rating\n",
    "            similarity_sum += similarities[index]\n",
    "\n",
    "    # Compute the predicted rating\n",
    "    if np.all(similarity_sum.toarray() > 0):\n",
    "        predicted_rating = weighted_sum / similarity_sum\n",
    "    else:\n",
    "        # Fallback: Use the average rating for the selected movie\n",
    "        movie_ratings = item_user_matrix[selected_movie_index, item_user_matrix[selected_movie_index].nonzero()[1]]\n",
    "        predicted_rating = np.mean(movie_ratings.toarray()) if movie_ratings.getnnz() > 0 else np.nan\n",
    "\n",
    "    print(f\"\\nPredicted rating for movie {selected_movie_index} by user {user_index}: {predicted_rating:.2f}\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "predict_rating(item_user_matrix, item_to_index=item_to_index, movie_title_dict=movie_title_dict, k=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Recommender prediction model 1 (with input function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements an item-based collaborative filtering approach to recommend movies. It utilizes cosine similarity to measure the similarity between movies and predicts ratings using a combination of global averages, user biases, and item biases.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "- `Item_Item_matrix`: Custom function item_item_matrix calculates the cosine similarity between two vectors, representing the similarity between movies based on user ratings.\n",
    "- `Bias Calculation`: Computes global average rating, user biases, and item biases to adjust predictions and account for systematic tendencies in the data.\n",
    "- `Rating Prediction`: The predict_ratings function predicts ratings for a set of movies (top-k similar items) for a given user, incorporating biases and similarities to generate personalized recommendations.\n",
    "\n",
    "**Recommendation Process:**\n",
    "\n",
    "1. Selects a movie and calculates similarities to all other movies.\n",
    "2. Identifies the top-k most similar movies.\n",
    "3. Predicts ratings for these movies for a specific user, using a weighted sum of the user's ratings adjusted by biases and similarity scores.\n",
    "\n",
    "**Outcome Display:**\n",
    "\n",
    "- Lists movies previously seen by the user related to the selected movie.\n",
    "- Shows the top-k recommended movies based on the calculated predictions, including their titles, genres, and the predicted ratings.\n",
    "- This approach enhances the recommendation process by providing more personalized and careful movie suggestions, leveraging detailed user-item interaction data and adjusting for individual and item-specific biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra I put the `find_movie_by_title`function, which uses `fuzzy string` (package) matching to identify and return the most similar movie title from the dataset based on a given search query. This enhances user experience by allowing for flexible movie searches, even when the exact titles are not known or are misspelled.\n",
    "\n",
    "- The `fuzzywuzzy` package is a tool for string matching that uses Levenshtein Distance to calculate the differences between sequences. It provides easy-to-use functions to compare strings and determine similarity, allowing for partial matches and typo tolerance in text comparison. This makes it particularly useful for searching titles.\n",
    "\n",
    "- -----> Levenshtein Distance is a measure of the minimum number of single-character edits required to change one string into another, including insertions, deletions, or substitutions. The Levenshtein Distance was introduced by the Soviet mathematician Vladimir Levenshtein in 1965. He described it as a metric to measure the difference between two sequences, which could be strings of characters, words, or any other ordered elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cosine similarity function\n",
    "def item_item_matrix(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "    return dot_product / norm_product if norm_product != 0 else 0\n",
    "\n",
    "# Define the user and item biases\n",
    "global_avg = np.mean(item_user_matrix[item_user_matrix > 0])\n",
    "user_biases = {user_index: np.mean(item_user_matrix[user_index, :][item_user_matrix[user_index, :] > 0]) - global_avg for user_index in range(item_user_matrix.shape[0])}\n",
    "item_biases = {item_index: np.mean(item_user_matrix[:, item_index][item_user_matrix[:, item_index] > 0]) - global_avg for item_index in range(item_user_matrix.shape[1])}\n",
    "\n",
    "\n",
    "def predict_ratings(item_user_matrix, user_index, top_k_items, item_to_index, index_to_item, global_avg, user_biases, item_biases):\n",
    "    \"\"\"Predict ratings for the top k recommended items for a given user, incorporating global average, user bias, and item bias.\"\"\"\n",
    "    predicted_ratings = []\n",
    "\n",
    "    for item_index, similarity in top_k_items:\n",
    "        if item_index in index_to_item:\n",
    "            movie_id = index_to_item[item_index]\n",
    "            item_matrix_index = item_to_index.get(movie_id, -1)\n",
    "            \n",
    "            if 0 <= item_matrix_index < item_user_matrix.shape[1]:\n",
    "                # Get the actual rating\n",
    "                user_rating = item_user_matrix[user_index, item_matrix_index]\n",
    "                # Check if the user has rated the item\n",
    "                if user_rating > 0:\n",
    "                    # Incorporate biases into the predicted rating\n",
    "                    user_bias = user_biases.get(user_index, 0)\n",
    "                    item_bias = item_biases.get(item_matrix_index, 0)\n",
    "                    # Calculate the weighted rating\n",
    "                    weighted_rating = global_avg + user_bias + item_bias + (similarity * (user_rating - (global_avg + user_bias + item_bias)))\n",
    "                    predicted_ratings.append((movie_id, weighted_rating))\n",
    "                else:\n",
    "                    # Predict rating based on global average and biases if the user hasn't rated the item\n",
    "                    predicted_ratings.append((movie_id, global_avg + user_biases.get(user_index, 0) + item_biases.get(item_matrix_index, 0)))\n",
    "            else:\n",
    "                # Default to global average if no rating information is available\n",
    "                predicted_ratings.append((movie_id, global_avg))\n",
    "    \n",
    "    return predicted_ratings\n",
    "\n",
    "\n",
    "def find_movie_by_title(movie_title_dict, search_query):\n",
    "    titles = list(movie_title_dict.values())\n",
    "    best_match = process.extractOne(search_query, titles)\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def recommend_movies(item_user_matrix, selected_movie_index, user_index, item_to_index, index_to_item, movie_title_dict, movie_genre_dict, k=10):\n",
    "    # Fetch the title of the selected movie for the outcome\n",
    "    selected_movie_title = movie_title_dict.get(index_to_item[selected_movie_index], \"Unknown Title\")\n",
    "\n",
    "    # Calculate cosine similarity between items\n",
    "    similarities = [(i, item_item_matrix(item_user_matrix[selected_movie_index, :].toarray().flatten(),\n",
    "                                        item_user_matrix[i, :].toarray().flatten())) for i in range(item_user_matrix.shape[0]) if i != selected_movie_index]\n",
    "    sorted_items = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    top_k_items = sorted_items[:k]\n",
    "\n",
    "    # Predict ratings for the top k items\n",
    "    predicted_ratings = predict_ratings(item_user_matrix, user_index, top_k_items, item_to_index, index_to_item, global_avg, user_biases, item_biases)\n",
    "    predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display the movies seen by the user related to the selected movie\n",
    "    movies_seen_indices = item_user_matrix[user_index, :].nonzero()[1]\n",
    "    movies_seen_titles = [movie_title_dict.get(index_to_item[i], \"Unknown Title\") for i in movies_seen_indices if i != selected_movie_index][:5]\n",
    "\n",
    "    print(f\"\\n5 movies seen by user {user_index} related to the selected movie '{movie_title_dict.get(index_to_item[selected_movie_index], 'Unknown')}':\")\n",
    "    for title in movies_seen_titles:\n",
    "        print(f\"- {title}\")\n",
    "\n",
    "    # Display the outcome\n",
    "    print(f\"\\nTop {k} recommended movies based on '{selected_movie_title}' with predicted ratings for user {user_index}:\\n\")\n",
    "    for movie_id, predicted_rating in predicted_ratings:\n",
    "        title = movie_title_dict.get(movie_id, \"Unknown Title\")\n",
    "        genre = movie_genre_dict.get(movie_id, \"Unknown Genre\")\n",
    "        print(f\"ItemID: {movie_id}, Title: \\033[1;32m{title}\\033[0m, Genre: {genre}, Predicted Rating: \\033[1;34m{predicted_rating:.2f}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 movies seen by user 5 related to the selected movie 'Forrest Gump (1994)':\n",
      "- Jumanji (1995)\n",
      "- Heat (1995)\n",
      "- Sabrina (1995)\n",
      "- Tom and Huck (1995)\n",
      "- Sudden Death (1995)\n",
      "\n",
      "Top 10 recommended movies based on 'Forrest Gump (1994)' with predicted ratings for user 5:\n",
      "\n",
      "ItemID: 296, Title: \u001b[1;32mPulp Fiction (1994)\u001b[0m, Genre: Comedy|Crime|Drama|Thriller, Predicted Rating: \u001b[1;34m4.94\u001b[0m\n",
      "ItemID: 1198, Title: \u001b[1;32mRaiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\u001b[0m, Genre: Action|Adventure, Predicted Rating: \u001b[1;34m4.91\u001b[0m\n",
      "ItemID: 260, Title: \u001b[1;32mStar Wars: Episode IV - A New Hope (1977)\u001b[0m, Genre: Action|Adventure|Sci-Fi, Predicted Rating: \u001b[1;34m4.63\u001b[0m\n",
      "ItemID: 318, Title: \u001b[1;32mShawshank Redemption, The (1994)\u001b[0m, Genre: Crime|Drama, Predicted Rating: \u001b[1;34m4.06\u001b[0m\n",
      "ItemID: 593, Title: \u001b[1;32mSilence of the Lambs, The (1991)\u001b[0m, Genre: Crime|Horror|Thriller, Predicted Rating: \u001b[1;34m3.97\u001b[0m\n",
      "ItemID: 1270, Title: \u001b[1;32mBack to the Future (1985)\u001b[0m, Genre: Adventure|Comedy|Sci-Fi, Predicted Rating: \u001b[1;34m3.55\u001b[0m\n",
      "ItemID: 1580, Title: \u001b[1;32mMen in Black (a.k.a. MIB) (1997)\u001b[0m, Genre: Action|Comedy|Sci-Fi, Predicted Rating: \u001b[1;34m3.53\u001b[0m\n",
      "ItemID: 480, Title: \u001b[1;32mJurassic Park (1993)\u001b[0m, Genre: Action|Adventure|Sci-Fi|Thriller, Predicted Rating: \u001b[1;34m3.38\u001b[0m\n",
      "ItemID: 2571, Title: \u001b[1;32mMatrix, The (1999)\u001b[0m, Genre: Action|Sci-Fi|Thriller, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 2762, Title: \u001b[1;32mSixth Sense, The (1999)\u001b[0m, Genre: Drama|Horror|Mystery, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# user_index = 5\n",
    "user_index = int(input(\"Enter a user index: \"))\n",
    "# search_query = \"Notebook\"\n",
    "search_query = input(\"Enter a movie title: \")\n",
    "\n",
    "best_match_title, score = find_movie_by_title(movie_title_dict, search_query)\n",
    "# Reverse lookup for movie titles to IDs\n",
    "movie_id = {title: id for id, title in movie_title_dict.items()}[best_match_title]\n",
    "selected_movie_index = item_to_index[movie_id]\n",
    "\n",
    "# Call the recommend_movies function with the found movie index\n",
    "recommend_movies(item_user_matrix, selected_movie_index, user_index, item_to_index, index_to_item, movie_title_dict, movie_genre_dict, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Recommender prediction model 2 \n",
    "#### With similarity score and given rating for seen movies by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the first Recommender prediction model, but:\n",
    "- This model displays the given rating for the seen movies for that user\n",
    "- Shows the highest similarity scores between the chosen movie and the movies seen by the user \n",
    "\n",
    "This recommendation model makes it more clear why certain recommendations are made with a certain rating. Because the rating the user gave to their seen movies are taken into account in the predicted rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cosine similarity function\n",
    "def item_item_matrix(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_product = np.linalg.norm(vector1) * np.linalg.norm(vector2)\n",
    "    return dot_product / norm_product if norm_product != 0 else 0\n",
    "\n",
    "# Define the user and item biases\n",
    "global_avg = np.mean(item_user_matrix[item_user_matrix > 0])\n",
    "user_biases = {user_index: np.mean(item_user_matrix[user_index, :][item_user_matrix[user_index, :] > 0]) - global_avg for user_index in range(item_user_matrix.shape[0])}\n",
    "item_biases = {item_index: np.mean(item_user_matrix[:, item_index][item_user_matrix[:, item_index] > 0]) - global_avg for item_index in range(item_user_matrix.shape[1])}\n",
    "\n",
    "def predict_ratings(item_user_matrix, user_index, top_k_items, item_to_index, index_to_item, global_avg, user_biases, item_biases):\n",
    "    \"\"\"Predict ratings for the top k recommended items for a given user, incorporating global average, user bias, and item bias.\"\"\"\n",
    "    predicted_ratings = []\n",
    "\n",
    "    for item_index, similarity in top_k_items:\n",
    "        if item_index in index_to_item:\n",
    "            movie_id = index_to_item[item_index]\n",
    "            item_matrix_index = item_to_index.get(movie_id, -1)\n",
    "            \n",
    "            if 0 <= item_matrix_index < item_user_matrix.shape[1]:\n",
    "                # Get the actual rating\n",
    "                user_rating = item_user_matrix[user_index, item_matrix_index]\n",
    "                # Check if the user has rated the item\n",
    "                if user_rating > 0:\n",
    "                    # Incorporate biases into the predicted rating\n",
    "                    user_bias = user_biases.get(user_index, 0)\n",
    "                    item_bias = item_biases.get(item_matrix_index, 0)\n",
    "                    # Calculate the weighted rating\n",
    "                    weighted_rating = global_avg + user_bias + item_bias + (similarity * (user_rating - (global_avg + user_bias + item_bias)))\n",
    "                    predicted_ratings.append((movie_id, weighted_rating))\n",
    "                else:\n",
    "                    # Predict rating based on global average and biases if the user hasn't rated the item\n",
    "                    predicted_ratings.append((movie_id, global_avg + user_biases.get(user_index, 0) + item_biases.get(item_matrix_index, 0)))\n",
    "            else:\n",
    "                # Default to global average if no rating information is available\n",
    "                predicted_ratings.append((movie_id, global_avg))\n",
    "    \n",
    "    return predicted_ratings\n",
    "\n",
    "\n",
    "def recommend_movies1(item_user_matrix, selected_movie_index, user_index, item_to_index, index_to_item, movie_title_dict, movie_genre_dict, k=10):\n",
    "    # Fetch the title of the selected movie for the outcome\n",
    "    selected_movie_title = movie_title_dict.get(index_to_item[selected_movie_index], \"Unknown Title\")\n",
    "\n",
    "    # Calculate cosine similarity between items\n",
    "    similarities = [(i, item_item_matrix(item_user_matrix[selected_movie_index, :].toarray().flatten(),\n",
    "                                        item_user_matrix[i, :].toarray().flatten())) for i in range(item_user_matrix.shape[0]) if i != selected_movie_index]\n",
    "    sorted_items = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    top_k_items = sorted_items[:k]\n",
    "\n",
    "    # Predict ratings for the top k items\n",
    "    predicted_ratings = predict_ratings(item_user_matrix, user_index, top_k_items, item_to_index, index_to_item, global_avg, user_biases, item_biases)\n",
    "    predicted_ratings = sorted(predicted_ratings, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    # Assuming 'similarities' is a list of tuples (movie_index, similarity_score) for all movies\n",
    "    similarities_dict = dict(similarities)  # Convert the list of tuples into a dictionary for easy access\n",
    "\n",
    "    # Display the movies seen by the user related to the selected movie along with their given ratings\n",
    "    movies_seen_indices = item_user_matrix[user_index, :].nonzero()[1]\n",
    "    movies_seen_info = []\n",
    "\n",
    "    for i in movies_seen_indices:\n",
    "        if i != selected_movie_index:  # Skip the selected movie\n",
    "            movie_id = index_to_item[i]  # Convert matrix index to movieId\n",
    "            title = movie_title_dict.get(movie_id, \"Unknown Title\")  # Fetch the title from dictionary\n",
    "            given_rating = item_user_matrix[user_index, i]  # Fetch the given rating by the user\n",
    "            similarity_score = similarities_dict.get(i, 0)  # Get the similarity score from the dictionary, default to 0 if not found\n",
    "            movies_seen_info.append((title, given_rating, similarity_score))\n",
    "\n",
    "    # Sort the seen movies by their similarity scores\n",
    "    movies_seen_info = sorted(movies_seen_info, key=lambda x: x[2], reverse=True)[:5]  # Sort by similarity score, limiting to 5\n",
    "\n",
    "    print(f\"5 movies seen by user {user_index} related to the selected movie '{movie_title_dict.get(index_to_item[selected_movie_index], 'Unknown')}':\\n\")\n",
    "    for title, rating, similarity in movies_seen_info:\n",
    "        print(f\"- {title}, Given Rating: {rating}, Similarity Score: {similarity:.2f}\")\n",
    "\n",
    "\n",
    "    # Display the outcome\n",
    "    print(f\"\\nTop 10 recommended movies based on '{selected_movie_title}' with predicted ratings for user {user_index}:\\n\")\n",
    "    for movie_id, predicted_rating in predicted_ratings:\n",
    "        title = movie_title_dict.get(movie_id, \"Unknown Title\")\n",
    "        genre = movie_genre_dict.get(movie_id, \"Unknown Genre\")\n",
    "        print(f\"ItemID: {movie_id}, Title: \\033[1;32m{title}\\033[0m, Genre: {genre}, Predicted Rating: \\033[1;34m{predicted_rating:.2f}\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 movies seen by user 4 related to the selected movie 'Toy Story (1995)':\n",
      "\n",
      "- Star Wars: Episode IV - A New Hope (1977), Given Rating: 4.0, Similarity Score: 0.92\n",
      "- Star Wars: Episode V - The Empire Strikes Back (1980), Given Rating: 3.0, Similarity Score: 0.91\n",
      "- Silence of the Lambs, The (1991), Given Rating: 4.0, Similarity Score: 0.91\n",
      "- Forrest Gump (1994), Given Rating: 2.5, Similarity Score: 0.91\n",
      "- Shawshank Redemption, The (1994), Given Rating: 3.0, Similarity Score: 0.91\n",
      "\n",
      "Top 10 recommended movies based on 'Toy Story (1995)' with predicted ratings for user 4:\n",
      "\n",
      "ItemID: 260, Title: \u001b[1;32mStar Wars: Episode IV - A New Hope (1977)\u001b[0m, Genre: Action|Adventure|Sci-Fi, Predicted Rating: \u001b[1;34m3.95\u001b[0m\n",
      "ItemID: 593, Title: \u001b[1;32mSilence of the Lambs, The (1991)\u001b[0m, Genre: Crime|Horror|Thriller, Predicted Rating: \u001b[1;34m3.85\u001b[0m\n",
      "ItemID: 3114, Title: \u001b[1;32mToy Story 2 (1999)\u001b[0m, Genre: Adventure|Animation|Children|Comedy|Fantasy, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 2571, Title: \u001b[1;32mMatrix, The (1999)\u001b[0m, Genre: Action|Sci-Fi|Thriller, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 2762, Title: \u001b[1;32mSixth Sense, The (1999)\u001b[0m, Genre: Drama|Horror|Mystery, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 4306, Title: \u001b[1;32mShrek (2001)\u001b[0m, Genre: Adventure|Animation|Children|Comedy|Fantasy|Romance, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 4886, Title: \u001b[1;32mMonsters, Inc. (2001)\u001b[0m, Genre: Adventure|Animation|Children|Comedy|Fantasy, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 2716, Title: \u001b[1;32mGhostbusters (a.k.a. Ghost Busters) (1984)\u001b[0m, Genre: Action|Comedy|Sci-Fi, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 4993, Title: \u001b[1;32mLord of the Rings: The Fellowship of the Ring, The (2001)\u001b[0m, Genre: Adventure|Fantasy, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 1270, Title: \u001b[1;32mBack to the Future (1985)\u001b[0m, Genre: Adventure|Comedy|Sci-Fi, Predicted Rating: \u001b[1;34m3.02\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "selected_movie_index =  0\n",
    "user_index =  4\n",
    "recommend_movies1(item_user_matrix, selected_movie_index, user_index, item_to_index, index_to_item, movie_title_dict, movie_genre_dict, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">3. Hyperparameter Tuning</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of item-based collaborative filtering, hyperparameter tuning focuses on optimizing the value of the hyperparameter K in the K-Nearest Neighbors (KNN) algorithm. The objective is to find the K value that maximizes the performance of the recommendation system. By systematically exploring various K values, we aim to enhance the accuracy and effectiveness of the model, ensuring it delivers the most relevant and precise movie recommendations to users. This process allows us to fine-tune the KNN model specifically for item-based collaborative filtering.\n",
    "\n",
    "- A `class` has been made in which a dataframe containing `itemid`, `userid`, and `rating` can be used to find the best K\n",
    "- --> in an optimal world you could just put millions and billions of datapoints in there, however, this datafrane I am going to use is already filtered in the beginning to optimise the computational efficiency\n",
    "\n",
    "- The explanation of the code is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tuning:\n",
    "    # Constructor for the Tuning class ()\n",
    "    def __init__(self):\n",
    "        self.train_data = None\n",
    "        self.validation_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    # Split the data into train, validation, and test\n",
    "    def train_test(self, sample_df):\n",
    "        # ititialize the sparse matrix for the (filtered) dataframe\n",
    "        item_user_matrix = csr_matrix(sample_df.pivot_table(index='itemid', columns='userid', values='rating').fillna(0).values)\n",
    "        # Split the data into train, validation, and test sets (train: 70%, validation: 15%, test: 15%)\n",
    "        train_data, test_validation_data = train_test_split(item_user_matrix, test_size=.3)\n",
    "        test_data, validation_data = train_test_split(test_validation_data, test_size=.5)\n",
    "\n",
    "        return train_data, validation_data, test_data\n",
    "\n",
    "    # Evaluate the predictions using RMSE and MAE\n",
    "    def evaluate_predictions(self, pred, truth):\n",
    "        # Using issparse() to check if the input is a sparse matrix\n",
    "        if issparse(pred):\n",
    "            pred = pred.toarray()\n",
    "        if issparse(truth):\n",
    "            truth = truth.toarray()\n",
    "        # Flatten the arrays if they are 2D because they are 1D arrays\n",
    "        if pred.ndim > 1:\n",
    "            pred = pred.flatten()\n",
    "        if truth.ndim > 1:\n",
    "            truth = truth.flatten()\n",
    "        # Filter out the missing values by checking if the rating is greater than 0\n",
    "        mask = truth > 0\n",
    "        filtered_pred = pred[mask]\n",
    "        filtered_truth = truth[mask]\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(filtered_truth, filtered_pred))\n",
    "        mae = mean_absolute_error(filtered_truth, filtered_pred)\n",
    "        \n",
    "        return rmse, mae\n",
    "\n",
    "    # Calculate the weighted KNN prediction\n",
    "    def calculate_weighted_knn_prediction(self, train_data, test_data, k=5, metric='cosine'):\n",
    "        # Initialize KNN model with cosine similarity metric and brute force algorithm because of its fast performance\n",
    "        knn_model = NearestNeighbors(n_neighbors=k, metric=metric, algorithm='brute', n_jobs=-1)\n",
    "        # Fit the model on the training data\n",
    "        knn_model.fit(train_data)\n",
    "        # Calculate the weighted KNN prediction with k-nearest neighbors package\n",
    "        distances, indices = knn_model.kneighbors(test_data)\n",
    "        # Prevent division by zero error\n",
    "        distances[distances == 0] = 1e-12\n",
    "        # Calculate the weights based on the distance to the k-nearest neighbors\n",
    "        weights = 1.0 / distances\n",
    "        # Calculate the weighted sum through averaging the ratings of the k-nearest neighbors for each test item\n",
    "        weighted_sum = np.array([np.average(train_data[indices[i]].toarray(), axis=0, weights=weights[i]) for i in range(test_data.shape[0])])\n",
    "        \n",
    "        return csr_matrix(weighted_sum)\n",
    "\n",
    "    def hyper_parameter_tuning_knn(self, dataset, iterations=10):\n",
    "        # Hyperparameter tuning by using k and metric\n",
    "        n_neighbors = [3, 7, 10, 15, 30, 40, 50, 55, 60, 65, 70, 75, 80, 100, 200, 400, 600]\n",
    "        # Only using cosine because of its computational efficiency (time constraints)\n",
    "        metrics =  ['cosine'] # 'euclidean','manhattan', 'minkowski']\n",
    "        # Initialize an empty list to store the results. hpt = hyperparameter tuning\n",
    "        hpt_results = []\n",
    "\n",
    "        for metric in metrics:\n",
    "            for k in n_neighbors:\n",
    "                rmse_list, mae_list = [], []\n",
    "                # Iterate through the specified number of iterations to find the best parameters\n",
    "                for _ in range(iterations):\n",
    "                    # Performs a train-test split to obtain training and validation sets for each iteration of the loop\n",
    "                    train_data, validation_data, _ = self.train_test(dataset)\n",
    "                    predictions = self.calculate_weighted_knn_prediction(train_data, validation_data, k=k, metric=metric)\n",
    "                    rmse, mae = self.evaluate_predictions(predictions, validation_data)\n",
    "                    \n",
    "                    rmse_list.append(rmse)\n",
    "                    mae_list.append(mae)\n",
    "                # Calculate the average RMSE and MAE for each k value in each iteration\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                avg_mae = np.mean(mae_list)\n",
    "\n",
    "                print(f'For k={k} using {metric}, the average RMSE={avg_rmse:.4f} and MAE={avg_mae:.4f}')\n",
    "                hpt_results.append([avg_rmse, metric, k, avg_mae])\n",
    "\n",
    "        # Sort the results by RMSE and return the best parameters\n",
    "        best_parameters = sorted(hpt_results, key=lambda x: x[0])[0]\n",
    "        print(f\"\\nBest Parameters: Metric={best_parameters[1]}, k={best_parameters[2]}, with RMSE={best_parameters[0]:.4f} and MAE={best_parameters[3]:.4f}\")\n",
    "\n",
    "        return best_parameters\n",
    "    \n",
    "    # Test the KNN model on the test set\n",
    "    def test_model_on_test_set(self, dataset, best_params_dict):\n",
    "        # Perform the data split\n",
    "        train_data, validation_data, test_data = self.train_test(dataset)\n",
    "\n",
    "        # Retrieve the best parameters\n",
    "        # Correctly accessing dictionary values\n",
    "        best_k = int(best_params_dict['k'])\n",
    "        best_metric = best_params_dict['metric']\n",
    "\n",
    "        # Train the model using the best parameters on the combined train and validation set\n",
    "        combined_train_data = vstack([train_data, validation_data])  # Combine using vstack\n",
    "\n",
    "        # Proceed with training the KNN model.\n",
    "        knn_model = NearestNeighbors(n_neighbors=best_k, metric=best_metric, algorithm='brute', n_jobs=-1)\n",
    "        #knn_model = NearestNeighbors(n_neighbors=best_params_dict['k'], metric=best_params_dict['metric'], algorithm='brute', n_jobs=-1) \n",
    "        knn_model.fit(combined_train_data)\n",
    "\n",
    "        # Predict on the test set\n",
    "        predictions = self.calculate_weighted_knn_prediction(combined_train_data, test_data, k=best_k, metric=best_metric)\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        test_rmse, test_mae = self.evaluate_predictions(predictions, test_data)\n",
    "\n",
    "        return test_rmse, test_mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of Hyperparameter Tuning class\n",
    "\n",
    "1. `__init__(self)`: This is the constructor method for the Tuning class. It initializes three attributes (train_data, validation_data, and test_data) to None. This ensures that they exist as attributes of the class from the beginning. This prevents attribute errors when accessing or manipulating them later in the code.\n",
    "\n",
    "2. `train_test(self, sample_df)`: This method is responsible for splitting the data into training, validation, and test sets. It takes a sample DataFrame sample_df as input, converts it into a sparse matrix representation, and then performs a 70-15-15 train-validation-test split on it. The training set (train_data) is used for model training, the validation set (validation_data) is used for hyperparameter tuning, and the test set (test_data) is used for final evaluation.\n",
    "\n",
    "3. `evaluate_predictions(self, pred, truth)`: This method evaluates the predictions made by a model using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). It takes two inputs: pred, the predicted ratings, and truth, the actual ratings. First, it checks if the inputs are sparse matrices and converts them into dense arrays if necessary. Then, it flattens the arrays, filters out missing values (ratings <= 0), and computes RMSE and MAE based on the filtered predictions and ground truth.\n",
    "\n",
    "4. `calculate_weighted_knn_prediction(self, train_data, test_data, k=5, metric='cosine')`: This method calculates predictions using a weighted K-nearest neighbors (KNN) approach. It takes train_data (training set), test_data (test set), k (number of neighbors), and metric (distance metric) as inputs. It initializes a KNN model with the specified parameters, fits it to the training data, and computes the weighted KNN prediction for the test data. It uses the inverse of distances as weights and averages the ratings of the K-nearest neighbors to predict the ratings for each test item.\n",
    "\n",
    "5. `hyper_parameter_tuning_knn(self, dataset, iterations=10)`: This method performs hyperparameter tuning for the KNN model. It takes a dataset and an optional parameter iterations (number of iterations for tuning) as inputs. It loops over different combinations of hyperparameters (k and metric), where k varies from a predefined list and metric is fixed to 'cosine' (can be altered to different metrics). Within each iteration, it splits the data into training and validation sets, calculates predictions using the weighted KNN method, evaluates the predictions using RMSE and MAE, and records the results. After iterating over all combinations, it selects the best parameters based on the lowest RMSE, prints the best parameters, and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=3 using cosine, the average RMSE=1.4665 and MAE=1.0926\n",
      "For k=7 using cosine, the average RMSE=1.3429 and MAE=1.0123\n",
      "For k=10 using cosine, the average RMSE=1.3090 and MAE=0.9898\n",
      "For k=15 using cosine, the average RMSE=1.2870 and MAE=0.9768\n",
      "For k=30 using cosine, the average RMSE=1.2676 and MAE=0.9693\n",
      "For k=40 using cosine, the average RMSE=1.2678 and MAE=0.9735\n",
      "For k=50 using cosine, the average RMSE=1.2590 and MAE=0.9685\n",
      "For k=55 using cosine, the average RMSE=1.2649 and MAE=0.9762\n",
      "For k=60 using cosine, the average RMSE=1.2588 and MAE=0.9713\n",
      "For k=65 using cosine, the average RMSE=1.2610 and MAE=0.9756\n",
      "For k=70 using cosine, the average RMSE=1.2623 and MAE=0.9781\n",
      "For k=75 using cosine, the average RMSE=1.2612 and MAE=0.9771\n",
      "For k=80 using cosine, the average RMSE=1.2609 and MAE=0.9792\n",
      "For k=100 using cosine, the average RMSE=1.2606 and MAE=0.9822\n",
      "For k=200 using cosine, the average RMSE=1.2947 and MAE=1.0338\n",
      "For k=400 using cosine, the average RMSE=1.3871 and MAE=1.1411\n",
      "For k=600 using cosine, the average RMSE=1.4946 and MAE=1.2573\n",
      "\n",
      "Best Parameters: Metric=cosine, k=60, with RMSE=1.2588 and MAE=0.9713\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Tuning class\n",
    "best_k_knn = Tuning()\n",
    "# Use the hyper_parameter_tuning_knn method to find the best KNN model parameters\n",
    "# Using 10 iterations because it takes a long time, and 10 iterations is quite average\n",
    "best_parameters = best_k_knn.hyper_parameter_tuning_knn(df_filtered, iterations=10)\n",
    "best_params_dict = {'metric': best_parameters[1], 'k': best_parameters[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for normal similarity approach: Test RMSE: 1.2414, Test MAE: 0.9574\n"
     ]
    }
   ],
   "source": [
    "# Test the KNN model on the test set using the best parameters found during hyperparameter tuning\n",
    "test_rmse_normal, test_mae_normal = best_k_knn.test_model_on_test_set(df_filtered, best_params_dict)\n",
    "print(f\"Results for normal similarity approach: Test RMSE: {test_rmse_normal:.4f}, Test MAE: {test_mae_normal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test results indicate that the (RMSE) is (), and the (MAE) is (). These metrics provide an assessment of the accuracy of the predictive model when applied to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Using Best Hyperparameter for Item-Based KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we indentified our best K, so we can use our best K (). So we can use that to incorporate that into our best recommender model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 movies seen by user 5 related to the selected movie 'Forrest Gump (1994)':\n",
      "\n",
      "- Back to the Future (1985), Given Rating: 3.5, Similarity Score: 0.93\n",
      "- Silence of the Lambs, The (1991), Given Rating: 4.0, Similarity Score: 0.93\n",
      "- Pulp Fiction (1994), Given Rating: 5.0, Similarity Score: 0.92\n",
      "- Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981), Given Rating: 5.0, Similarity Score: 0.92\n",
      "- Men in Black (a.k.a. MIB) (1997), Given Rating: 3.5, Similarity Score: 0.92\n",
      "\n",
      "Top 10 recommended movies based on 'Forrest Gump (1994)' with predicted ratings for user 5:\n",
      "\n",
      "ItemID: 296, Title: \u001b[1;32mPulp Fiction (1994)\u001b[0m, Genre: Comedy|Crime|Drama|Thriller, Predicted Rating: \u001b[1;34m4.94\u001b[0m\n",
      "ItemID: 589, Title: \u001b[1;32mTerminator 2: Judgment Day (1991)\u001b[0m, Genre: Action|Sci-Fi, Predicted Rating: \u001b[1;34m4.92\u001b[0m\n",
      "ItemID: 1198, Title: \u001b[1;32mRaiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\u001b[0m, Genre: Action|Adventure, Predicted Rating: \u001b[1;34m4.91\u001b[0m\n",
      "ItemID: 457, Title: \u001b[1;32mFugitive, The (1993)\u001b[0m, Genre: Thriller, Predicted Rating: \u001b[1;34m4.85\u001b[0m\n",
      "ItemID: 260, Title: \u001b[1;32mStar Wars: Episode IV - A New Hope (1977)\u001b[0m, Genre: Action|Adventure|Sci-Fi, Predicted Rating: \u001b[1;34m4.63\u001b[0m\n",
      "ItemID: 1527, Title: \u001b[1;32mFifth Element, The (1997)\u001b[0m, Genre: Action|Adventure|Comedy|Sci-Fi, Predicted Rating: \u001b[1;34m4.48\u001b[0m\n",
      "ItemID: 110, Title: \u001b[1;32mBraveheart (1995)\u001b[0m, Genre: Action|Drama|War, Predicted Rating: \u001b[1;34m4.43\u001b[0m\n",
      "ItemID: 1, Title: \u001b[1;32mToy Story (1995)\u001b[0m, Genre: Adventure|Animation|Children|Comedy|Fantasy, Predicted Rating: \u001b[1;34m4.41\u001b[0m\n",
      "ItemID: 1097, Title: \u001b[1;32mE.T. the Extra-Terrestrial (1982)\u001b[0m, Genre: Children|Drama|Sci-Fi, Predicted Rating: \u001b[1;34m4.39\u001b[0m\n",
      "ItemID: 1214, Title: \u001b[1;32mAlien (1979)\u001b[0m, Genre: Horror|Sci-Fi, Predicted Rating: \u001b[1;34m4.35\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recommend_movies1(item_user_matrix, selected_movie_index, user_index, item_to_index, index_to_item, movie_title_dict, movie_genre_dict, k=best_parameters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">4. Item-Based Classification using KNN</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-Bases Classification using KNN, `item_item_similarity`, is designed to calculate the similarities between a specific item and other items based on interactions from users. It begins by transforming a sparse matrix that represents these interactions into a dense array for straightforward computation. Following this, the function iterates over each item, excluding the selected one, to compute the cosine similarity between their interaction vectors. It returns a list of tuples, with each tuple comprising the index of another item and the similarity score with the selected item. Subsequently, a random item index is selected, and similarities between this item and others are calculated. The resulting similarities are then sorted in descending order, and the top 20 similar items are presented along with their similarity scores. This process essentially aids in analyzing item-item similarities based on user interaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSimilarityCalculator:\n",
    "    def __init__(self, item_user_matrix, movie_titles):\n",
    "        # Check if the input data is valid\n",
    "        if item_user_matrix.ndim != 2 or item_user_matrix.size == 0:\n",
    "            raise ValueError(\"item_user_matrix must be a non-empty 2D numpy array.\")\n",
    "        if not isinstance(movie_titles, dict):\n",
    "            raise ValueError(\"movie_titles must be a dictionary mapping movie IDs to titles.\")\n",
    "        \n",
    "        self.item_user_matrix = item_user_matrix\n",
    "        self.movie_titles = movie_titles\n",
    "        self.similarity_matrix = None\n",
    "    # Compute the similarity matrix\n",
    "    def compute_similarity_matrix(self):\n",
    "        self.similarity_matrix = cosine_similarity(self.item_user_matrix)\n",
    "        \n",
    "    # Get the top k similar movies\n",
    "    def get_top_k_similar_movies(self, movie_id, k=5):\n",
    "        if self.similarity_matrix is None:\n",
    "            self.compute_similarity_matrix()\n",
    "            # Get the index of the movie in the matrix\n",
    "        movie_index = movie_id - 1  # Adjust for 0-based indexing\n",
    "        # Get the similarity scores for the movie\n",
    "        movie_similarities = self.similarity_matrix[movie_index]\n",
    "        # Get the top k similar movies\n",
    "        top_k_indices = np.argsort(movie_similarities)[-k-1:-1][::-1]\n",
    "        top_k_indices = [index + 1 for index in top_k_indices]  # Adjust back to 1-based indexing\n",
    "        top_k_scores = [movie_similarities[index - 1] for index in top_k_indices]\n",
    "        # Include movie titles in the results and filter out \"Title Unknown\"\n",
    "        top_k_results = [(index, self.movie_titles.get(index, \"Title Unknown\"), score)\n",
    "                        for index, score in zip(top_k_indices, top_k_scores)\n",
    "                        if self.movie_titles.get(index, \"Title Unknown\") != \"Title Unknown\"]\n",
    "        # Return only results with known titles, up to k or the actual number of known titles found\n",
    "        return top_k_results[:k]\n",
    "    \n",
    "    def print_top_k_similar_movies(self, movie_id, k=5, display_count=10):\n",
    "        # Call the get_top_k_similar_movies method\n",
    "        top_similar_movies = self.get_top_k_similar_movies(movie_id, k)\n",
    "        # If unknown movie skip the output\n",
    "        known_movies_count = min(len(top_similar_movies), display_count)\n",
    "        print(f\"Top {known_movies_count} known similar items to '{self.movie_titles.get(movie_id, 'Title Unknown')}' (ID {movie_id}), from top {k} similarities computed:\")\n",
    "        for idx, (movie_id, title, score) in enumerate(top_similar_movies[:display_count], start=1):\n",
    "            print(f\"{idx}. '{title}' (ID {movie_id}) with similarity score: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 known similar items to 'American President, The (1995)' (ID 11), from top 50 similarities computed:\n",
      "1. 'Being Human (1993)' (ID 418) with similarity score: 0.7694\n",
      "2. 'Renaissance Man (1994)' (ID 516) with similarity score: 0.7279\n",
      "3. 'Terminator, The (1984)' (ID 1240) with similarity score: 0.7246\n",
      "4. 'Friday the 13th Part VI: Jason Lives (1986)' (ID 1979) with similarity score: 0.7222\n",
      "5. 'Name of the Rose, The (Name der Rose, Der) (1986)' (ID 2467) with similarity score: 0.7201\n",
      "6. 'Thumbelina (1994)' (ID 2876) with similarity score: 0.7169\n",
      "7. 'Mina Tannenbaum (1994)' (ID 1163) with similarity score: 0.7150\n",
      "8. 'City Slickers II: The Legend of Curly's Gold (1994)' (ID 432) with similarity score: 0.7121\n",
      "9. 'Chasers (1994)' (ID 564) with similarity score: 0.7120\n",
      "10. 'Coneheads (1993)' (ID 435) with similarity score: 0.7084\n"
     ]
    }
   ],
   "source": [
    "similarity_calculator = SimpleSimilarityCalculator(item_user_matrix, movie_title_dict)\n",
    "similarity_calculator.print_top_k_similar_movies((11), k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- --> The provided list identifies the top 10 movies most similar to 'American President, The (1995)' (ID 11) based on computed similarities, out of a total of 50 similarities calculated. Each movie in the list is accompanied by its ID, title, and similarity score, indicating how closely it relates to the target movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ItemBasedKNNClassifier \n",
    "- Which implements a simple item-based k-nearest neighbors (KNN) classifier for recommending item categories based on item-item similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'genre' string into lists and then explode.\n",
    "# This directly avoids creating an unnecessary copy of movies DataFrame.\n",
    "df_filtered['genre'] = df_filtered['genre'].str.split('|')\n",
    "df_exploded = df_filtered.explode('genre').reset_index(drop=True)\n",
    "\n",
    "# Directly obtain unique 'itemid' values in the order they appear, which should match item_user_matrix_row_order\n",
    "# This step assumes df_filtered's 'itemid' are in the same order as item_user_matrix's rows.\n",
    "unique_itemids_ordered = df_filtered['itemid'].drop_duplicates().values\n",
    "\n",
    "# Drop duplicates while keeping the first genre listed for each item without reindexing\n",
    "unique_items_with_genre = df_exploded.drop_duplicates(subset=['itemid'])\n",
    "\n",
    "# directly map each 'itemid' to its genre without additional DataFrame operations.\n",
    "item_categories = np.array([unique_items_with_genre.loc[unique_items_with_genre['itemid'] == itemid, 'genre'].values[0] for itemid in unique_itemids_ordered])\n",
    "\n",
    "#item_titles = pd.Series(df_filtered['title'].values, index=df_filtered['itemid']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- Given an item ID, this model predicts the category of that item by finding its k most similar items based on the computed similarity matrix. It then returns the most common category among these similar items as the predicted category for the given item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedKNNClassifier:\n",
    "    def __init__(self, item_user_matrix, item_categories):\n",
    "        self.item_user_matrix = item_user_matrix\n",
    "        self.item_categories = item_categories\n",
    "        self.similarity_matrix = None\n",
    "\n",
    "    def item_item_matrix(self):\n",
    "        # Compute cosine similarity, ensuring the output is dense\n",
    "        self.similarity_matrix = cosine_similarity(self.item_user_matrix, dense_output=True)\n",
    "    \n",
    "    def predict_category(self, item_id, k=5):\n",
    "        if self.similarity_matrix is None:\n",
    "            self.item_item_matrix()\n",
    "        item_index = item_id - 1\n",
    "        item_similarities = self.similarity_matrix[item_index]\n",
    "        top_k_indices = np.argsort(item_similarities)[-k-1:-1][::-1]\n",
    "        top_k_categories = [self.item_categories[index] for index in top_k_indices]\n",
    "        most_common_category, _ = Counter(top_k_categories).most_common(1)[0]\n",
    "        return most_common_category\n",
    "    \n",
    "    def print_top_k_similar_items(self, item_id, k=5):\n",
    "        if self.similarity_matrix is None:\n",
    "            self.item_item_matrix()\n",
    "        item_index = item_id - 1\n",
    "        item_similarities = self.similarity_matrix[item_index]\n",
    "        top_k_indices = np.argsort(item_similarities)[-k-1:-1][::-1]\n",
    "        top_k_indices = [index + 1 for index in top_k_indices]  # Adjusting for 1-based indexing\n",
    "        top_k_scores = [item_similarities[index - 1] for index in top_k_indices]\n",
    "        print(f\"Top {k} similar items to Item {item_id}:\")\n",
    "        for index, score in zip(top_k_indices, top_k_scores):\n",
    "            print(f\"Item {index} with similarity score: {score:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category for Item 1: Drama\n",
      "Predicted category for Item 2: Comedy\n",
      "Predicted category for Item 3: Action\n",
      "Predicted category for Item 4: Comedy\n",
      "Predicted category for Item 5: Comedy\n",
      "Predicted category for Item 6: Comedy\n",
      "Predicted category for Item 7: Action\n",
      "Predicted category for Item 8: Action\n",
      "Predicted category for Item 9: Comedy\n",
      "Predicted category for Item 10: Comedy\n",
      "Predicted category for Item 11: Action\n",
      "Predicted category for Item 12: Action\n",
      "Predicted category for Item 13: Comedy\n",
      "Predicted category for Item 14: Action\n",
      "Predicted category for Item 15: Comedy\n"
     ]
    }
   ],
   "source": [
    "classifier_cat = ItemBasedKNNClassifier(item_user_matrix, item_categories)\n",
    "for item_id in range(1, 16):\n",
    "    predicted_category = classifier_cat.predict_category(item_id=item_id, k=70)\n",
    "    print(f\"Predicted category for Item {item_id}: {predicted_category}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Predicted category for Item 1: Drama\" indicates that the predicted category for Item 1 is Drama.\n",
    "- \"Predicted category for Item 2: Comedy\" indicates that the predicted category for Item 2 is Comedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ItemBasedKNNRatingPredictor\n",
    "\n",
    "This is based on using an item-based collaborative filtering approach with the k-nearest neighbors (KNN) algorithm.\n",
    "\n",
    "This class is to predict user ratings for items (movies) by leveraging item-item similarity computed through cosine similarity, providing personalized recommendations to users based on their preferences and previous interactions with items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedKNNRatingPredictor:\n",
    "    def __init__(self, item_user_matrix, movie_titles):\n",
    "        self.item_user_matrix = item_user_matrix\n",
    "        self.movie_titles = movie_titles  # Add movie titles as a class attribute\n",
    "        self.similarity_matrix = None\n",
    "\n",
    "    def item_item_matrix(self):\n",
    "        # Ensure the matrix is in dense format for the dot product calculation\n",
    "        dense_matrix = self.item_user_matrix.toarray()\n",
    "        # Compute the magnitude of item vectors\n",
    "        magnitude = np.sqrt(np.square(dense_matrix).sum(axis=1))\n",
    "        # To avoid division by zero, replace zeros with very small number\n",
    "        magnitude[magnitude == 0] = 1e-10\n",
    "        # Normalize the item vectors\n",
    "        normalized_matrix = dense_matrix / magnitude[:, np.newaxis]\n",
    "        # Compute cosine similarity as dot product of normalized item vectors\n",
    "        self.similarity_matrix = np.dot(normalized_matrix, normalized_matrix.T)\n",
    "\n",
    "    def predict_rating(self, user_id, item_id, k=5, include_title=True):\n",
    "        if self.similarity_matrix is None:\n",
    "            self.item_item_matrix()\n",
    "        \n",
    "        user_ratings = self.item_user_matrix[:, user_id].toarray().flatten()\n",
    "        item_similarities = self.similarity_matrix[item_id - 1]\n",
    "        \n",
    "        non_zero_ratings = user_ratings > 0\n",
    "        non_zero_similarities = item_similarities * non_zero_ratings\n",
    "        top_k_indices = np.argsort(non_zero_similarities)[-k:]\n",
    "        \n",
    "        top_k_similarities = item_similarities[top_k_indices]\n",
    "        top_k_ratings = user_ratings[top_k_indices]\n",
    "        \n",
    "        if top_k_similarities.sum() == 0:\n",
    "            return (0, self.movie_titles[item_id]) if include_title else 0\n",
    "        \n",
    "        predicted_rating = np.dot(top_k_similarities, top_k_ratings) / top_k_similarities.sum()\n",
    "        \n",
    "        return (predicted_rating, self.movie_titles[item_id]) if include_title else predicted_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for 'Pulp Fiction (1994)' by User 500: 3.04\n"
     ]
    }
   ],
   "source": [
    "classifier = ItemBasedKNNRatingPredictor(item_user_matrix, movie_titles=movie_title_dict)\n",
    "predicted_rating, movie_title = classifier.predict_rating(500, 296, k=5, include_title=True)\n",
    "print(f\"Predicted rating for '{movie_title}' by User 500: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">5. Netflix and Yelp</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the item-based CF KNN on the Netflix and Yelp dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; background: linear-gradient(to top right, #222, #000); padding: 20px; color: #E50914;\">\n",
    "    <h3 style=\"font-weight: bold; font-size: 30px;\">5.1 Netflix</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data_filtering function created in the beginning to easily filter the netlfix dataset for computational efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing users who have rated less than 10.0% of all movies\n",
      "Filtered dataset size after removing less active users: 8040274\n",
      "\n",
      "Removing movies that have been rated by fewer than 75 users\n",
      "Filtered dataset size after removing less rated movies: 8037899\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1488844</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>Documentary|Animation|Family</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>558634</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>Documentary|Animation|Family</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1181550</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>Documentary|Animation|Family</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1227322</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>Documentary|Animation|Family</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>786312</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "      <td>Documentary|Animation|Family</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userid  itemid  rating            title                         genre  \\\n",
       "0   1488844       1       3  Dinosaur Planet  Documentary|Animation|Family   \n",
       "22   558634       1       4  Dinosaur Planet  Documentary|Animation|Family   \n",
       "24  1181550       1       3  Dinosaur Planet  Documentary|Animation|Family   \n",
       "25  1227322       1       4  Dinosaur Planet  Documentary|Animation|Family   \n",
       "31   786312       1       3  Dinosaur Planet  Documentary|Animation|Family   \n",
       "\n",
       "    year  \n",
       "0   2003  \n",
       "22  2003  \n",
       "24  2003  \n",
       "25  2003  \n",
       "31  2003  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "netflix = parquet.read_table('/Users/sandervanduin/Desktop/CSV_parquet/content.parquet')\n",
    "# Read the dataset into a pandas dataframe\n",
    "netflix = netflix.to_pandas()\n",
    "# Filter the dataset\n",
    "netflix_filtered = data_filtering(netflix, mimimum_percentage_movies_user_rated=0.1, minimum_ratings_per_movie=75)\n",
    "netflix_filtered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=3 using cosine, the average RMSE=1.3855 and MAE=1.0315\n",
      "For k=7 using cosine, the average RMSE=1.2686 and MAE=0.9564\n",
      "For k=10 using cosine, the average RMSE=1.2383 and MAE=0.9358\n",
      "For k=15 using cosine, the average RMSE=1.2087 and MAE=0.9162\n",
      "For k=30 using cosine, the average RMSE=1.1842 and MAE=0.9003\n",
      "For k=40 using cosine, the average RMSE=1.1712 and MAE=0.8918\n",
      "For k=50 using cosine, the average RMSE=1.1671 and MAE=0.8899\n",
      "For k=55 using cosine, the average RMSE=1.1577 and MAE=0.8836\n",
      "For k=60 using cosine, the average RMSE=1.1608 and MAE=0.8862\n",
      "For k=65 using cosine, the average RMSE=1.1639 and MAE=0.8897\n",
      "For k=70 using cosine, the average RMSE=1.1585 and MAE=0.8859\n",
      "For k=75 using cosine, the average RMSE=1.1576 and MAE=0.8858\n",
      "For k=80 using cosine, the average RMSE=1.1576 and MAE=0.8860\n",
      "For k=100 using cosine, the average RMSE=1.1554 and MAE=0.8865\n",
      "For k=200 using cosine, the average RMSE=1.1751 and MAE=0.9134\n",
      "For k=400 using cosine, the average RMSE=1.2439 and MAE=0.9873\n",
      "For k=600 using cosine, the average RMSE=1.3192 and MAE=1.0662\n",
      "\n",
      "Best Parameters: Metric=cosine, k=100, with RMSE=1.1554 and MAE=0.8865\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Tuning class\n",
    "best_k_knn_netflix = Tuning()\n",
    "# Use the hyper_parameter_tuning_knn method to find the best KNN model parameters\n",
    "# Using 10 iterations to find the best parameters\n",
    "best_parameters_netflix = best_k_knn_netflix.hyper_parameter_tuning_knn(netflix_filtered, iterations=10)\n",
    "best_params_dict_netflix = {'k': best_parameters_netflix[0], 'metric': best_parameters_netflix[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of hyper parameter tuning of the Netflix dataset\n",
    "\n",
    "Best parameters:\n",
    "\n",
    "- K=100, with an average RMSE=1.1554 and the MAE=0.8865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for normal similarity approach: Test RMSE: 1.7210, Test MAE: 1.2000\n"
     ]
    }
   ],
   "source": [
    "# Test the KNN model on the test set using the best parameters found during hyperparameter tuning\n",
    "test_rmse_normal, test_mae_normal = best_k_knn_netflix.test_model_on_test_set(netflix_filtered, best_params_dict_netflix)\n",
    "print(f\"Results for normal similarity approach: Test RMSE: {test_rmse_normal:.4f}, Test MAE: {test_mae_normal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test results indicate that the (RMSE) is (1.7210), and the (MAE) is (1.2000). These metrics provide an assessment of the accuracy of the predictive model when applied to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the best K for our recommender system for Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 movies seen by user 9 related to the selected movie 'Paula Abdul's Get Up & Dance':\n",
      "\n",
      "- Peter Tosh: Stepping Razor: Red X, Given Rating: 3.0, Similarity Score: 0.34\n",
      "- Ultimate Crop Circles: Signs From Space?, Given Rating: 5.0, Similarity Score: 0.30\n",
      "- Tridev, Given Rating: 3.0, Similarity Score: 0.29\n",
      "- Coral Sea Dreaming, Given Rating: 3.0, Similarity Score: 0.25\n",
      "- On Our Merry Way, Given Rating: 5.0, Similarity Score: 0.24\n",
      "\n",
      "Top 10 recommended movies based on 'Paula Abdul's Get Up & Dance' with predicted ratings for user 9:\n",
      "\n",
      "ItemID: 950, Title: \u001b[1;32mExplosive Dance\u001b[0m, Genre: Music, Predicted Rating: \u001b[1;34m4.11\u001b[0m\n",
      "ItemID: 1690, Title: \u001b[1;32mSavage Garden: Superstars and Cannonballs\u001b[0m, Genre: Documentary|Music, Predicted Rating: \u001b[1;34m3.79\u001b[0m\n",
      "ItemID: 1053, Title: \u001b[1;32mMysteries of Magic: Vol. 1\u001b[0m, Genre: Documentary, Predicted Rating: \u001b[1;34m3.66\u001b[0m\n",
      "ItemID: 1643, Title: \u001b[1;32mRules: Pyaar Ka Superhit Formula\u001b[0m, Genre: Comedy|Romance, Predicted Rating: \u001b[1;34m3.62\u001b[0m\n",
      "ItemID: 787, Title: \u001b[1;32mLa Vallee\u001b[0m, Genre: Drama, Predicted Rating: \u001b[1;34m3.50\u001b[0m\n",
      "ItemID: 2052, Title: \u001b[1;32mDarrin's Dance Grooves\u001b[0m, Genre: Documentary, Predicted Rating: \u001b[1;34m3.29\u001b[0m\n",
      "ItemID: 3516, Title: \u001b[1;32mIn the Face of Evil: Reagan's War in Word and Deed\u001b[0m, Genre: Documentary, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 3620, Title: \u001b[1;32mNothing Funny\u001b[0m, Genre: Comedy|Drama, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 6995, Title: \u001b[1;32mBlackboards\u001b[0m, Genre: Drama|War, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n",
      "ItemID: 5098, Title: \u001b[1;32mPyaar Ishq aur Mohabbat\u001b[0m, Genre: Drama|Musical|Romance, Predicted Rating: \u001b[1;34m3.23\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Creating item_user_matrix for Netflix dataset\n",
    "item_user_matrix_netflix = csr_matrix(netflix_filtered.pivot_table(index='itemid', columns='userid', values='rating').fillna(0).values)\n",
    "movie_title_netlix = pd.Series(netflix_filtered['title'].values, index=netflix_filtered['itemid']).to_dict()\n",
    "movie_genre_netflix = pd.Series(netflix_filtered['genre'].values, index=netflix_filtered['itemid']).to_dict()\n",
    "item_ids = netflix_filtered['itemid'].unique()\n",
    "item_to_index_netflix = {item: index for index, item in enumerate(item_ids)}\n",
    "index_to_item_netflix = {index: item for item, index in item_to_index_netflix.items()}\n",
    "\n",
    "selected_movie_index_netflix = 2\n",
    "user_index_netflix = 9\n",
    "\n",
    "\n",
    "# Recommending movies with the best parameters for the Netflix dataset\n",
    "recommend_movies1(item_user_matrix_netflix, selected_movie_index_netflix, user_index_netflix, item_to_index_netflix, index_to_item_netflix, movie_title_netlix, movie_genre_netflix, k=best_parameters_netflix[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #ffffff; padding: 20px; color: #d32323; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0; color: #d32323;\">5.2 Yelp</h2>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jOAQZb1EQAP-XRfERcwcqA</td>\n",
       "      <td>79730</td>\n",
       "      <td>4362</td>\n",
       "      <td>2</td>\n",
       "      <td>My main course was seasoning with a side of me...</td>\n",
       "      <td>2021-08-29 06:39:41</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DM7rItbtqUXEtH5a31fymg</td>\n",
       "      <td>35547</td>\n",
       "      <td>4433</td>\n",
       "      <td>2</td>\n",
       "      <td>Bottom line, go to Cleavers if you're looking ...</td>\n",
       "      <td>2016-09-15 20:17:54</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j6J5369TLP61vcl-hKa8ZQ</td>\n",
       "      <td>1853</td>\n",
       "      <td>4479</td>\n",
       "      <td>3</td>\n",
       "      <td>Had the chance to visit for the first time sin...</td>\n",
       "      <td>2018-04-21 20:52:02</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rv7LiJpxniNfDnMEh-PynA</td>\n",
       "      <td>58690</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>I came for business and only stayed one night ...</td>\n",
       "      <td>2013-08-30 16:47:40</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>2013</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GnepwdTkZpMSr3xYPYzr9g</td>\n",
       "      <td>82344</td>\n",
       "      <td>5455</td>\n",
       "      <td>4</td>\n",
       "      <td>Two Chicks CafÃ© is a cute place with fantastic...</td>\n",
       "      <td>2019-02-17 20:30:36</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id  user_id  business_id  stars  \\\n",
       "0  jOAQZb1EQAP-XRfERcwcqA    79730         4362      2   \n",
       "1  DM7rItbtqUXEtH5a31fymg    35547         4433      2   \n",
       "2  j6J5369TLP61vcl-hKa8ZQ     1853         4479      3   \n",
       "3  Rv7LiJpxniNfDnMEh-PynA    58690           86      4   \n",
       "4  GnepwdTkZpMSr3xYPYzr9g    82344         5455      4   \n",
       "\n",
       "                                                text                date  day  \\\n",
       "0  My main course was seasoning with a side of me... 2021-08-29 06:39:41   29   \n",
       "1  Bottom line, go to Cleavers if you're looking ... 2016-09-15 20:17:54   15   \n",
       "2  Had the chance to visit for the first time sin... 2018-04-21 20:52:02   21   \n",
       "3  I came for business and only stayed one night ... 2013-08-30 16:47:40   30   \n",
       "4  Two Chicks CafÃ© is a cute place with fantastic... 2019-02-17 20:30:36   17   \n",
       "\n",
       "   month  year  hour  minute  second  \n",
       "0      8  2021     6      39      41  \n",
       "1      9  2016    20      17      54  \n",
       "2      4  2018    20      52       2  \n",
       "3      8  2013    16      47      40  \n",
       "4      2  2019    20      30      36  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "yelp_original = parquet.read_table(\"/Users/sandervanduin/Desktop/CSV_parquet/model_review_df.parquet\")\n",
    "names = parquet.read_table(\"/Users/sandervanduin/Desktop/CSV_parquet/model_business_df.parquet\")\n",
    "# Read the dataset into a pandas dataframe\n",
    "yelp_original = yelp_original.to_pandas()\n",
    "\n",
    "yelp_original.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>68281</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>94153</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>76301</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786</th>\n",
       "      <td>21595</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>84635</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid  itemid  rating\n",
       "2007   68281       6       1\n",
       "5053   94153       7       4\n",
       "5732   76301       7       5\n",
       "6786   21595       8       5\n",
       "7000   84635       9       3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp1 = yelp_original[['user_id', 'business_id', 'stars']]\n",
    "yelp = yelp1.rename(columns={'stars': 'rating', 'business_id': 'itemid', 'user_id': 'userid'})\n",
    "# sort on itemid\n",
    "yelp = yelp.sort_values('itemid')\n",
    "yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=3 using cosine, the average RMSE=3.4445 and MAE=2.9967\n",
      "For k=7 using cosine, the average RMSE=3.4930 and MAE=3.0805\n",
      "\n",
      "Best Parameters: Metric=cosine, k=3, with RMSE=3.4445 and MAE=2.9967\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Tuning class\n",
    "best_k_knn_yelp = Tuning()\n",
    "# Use the hyper_parameter_tuning_knn method to find the best KNN model parameters\n",
    "best_parameters_yelp = best_k_knn_yelp.hyper_parameter_tuning_knn(yelp, iterations=1)\n",
    "best_parameters_yelp_dict = {'k': best_parameters_yelp[0], 'metric': best_parameters_yelp[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for normal similarity approach: Test RMSE: 3.4745, Test MAE: 3.0635\n"
     ]
    }
   ],
   "source": [
    "# Test the KNN model on the test set using the best parameters found during hyperparameter tuning\n",
    "test_rmse_normal, test_mae_normal = best_k_knn_yelp.test_model_on_test_set(yelp, best_parameters_yelp_dict)\n",
    "print(f\"Results for normal similarity approach: Test RMSE: {test_rmse_normal:.4f}, Test MAE: {test_mae_normal:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test results indicate that the (RMSE) is (3.4745), and the (MAE) is (3.0635). These metrics provide an assessment of the accuracy of the predictive model when applied to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tsevi's Pub And Grill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sonic Drive-In</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid                     title\n",
       "0       0        St Honore Pastries\n",
       "1       1  Perkiomen Valley Brewery\n",
       "2       2            Sonic Drive-In\n",
       "3       3     Tsevi's Pub And Grill\n",
       "4       4            Sonic Drive-In"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = names.to_pandas()\n",
    "names = names.rename(columns={'business_id': 'itemid', 'name': 'title'})\n",
    "# Only include the columns we need in the dataset for the recommender system model (only the itemid and title columns)\n",
    "names_yelp = names[['itemid', 'title']]\n",
    "names_yelp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68281</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Denny's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94153</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Zio's Italian Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76301</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Zio's Italian Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21595</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuna Bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84635</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>BAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23015</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>BAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42702</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>BAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69748</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>BAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45858</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Romano's Macaroni Grill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Romano's Macaroni Grill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>58146</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Bar One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62454</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>Tony's Restaurant &amp; 3rd Street Cafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userid  itemid  rating                                title\n",
       "0    68281       6       1                              Denny's\n",
       "1    94153       7       4                 Zio's Italian Market\n",
       "2    76301       7       5                 Zio's Italian Market\n",
       "3    21595       8       5                             Tuna Bar\n",
       "4    84635       9       3                                  BAP\n",
       "5    23015       9       4                                  BAP\n",
       "6    42702       9       4                                  BAP\n",
       "7    69748       9       5                                  BAP\n",
       "8    45858      12       1              Romano's Macaroni Grill\n",
       "9    64102      12       3              Romano's Macaroni Grill\n",
       "10   58146      15       3                              Bar One\n",
       "11   62454      21       5  Tony's Restaurant & 3rd Street Cafe"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge yelp with names on business_id\n",
    "yelp_with_names = pd.merge(yelp, names_yelp, on='itemid')\n",
    "yelp_with_names.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_user_matrix_yelp = csr_matrix(yelp.pivot_table(index='itemid', columns='userid', values='rating').fillna(0).values)\n",
    "# put yelp_with_names into a dictionary\n",
    "movie_title_dict_yelp = yelp_with_names.set_index('itemid')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I was not able to use my main recommender model to predict restaurants and ratings.\n",
    "\n",
    "- --> Since the Yelp dataset does not have movie titles nor genre, we will use the SimpleSimilarityCalculator to find out the most similar restaurants for Denny's (ID 6) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 known similar items to 'Denny's' (ID 6), from top 70 similarities computed:\n",
      "1. 'Denny's' (ID 6) with similarity score: 1.0000\n",
      "2. 'The Hattery Stove & Still' (ID 1654) with similarity score: 0.2872\n",
      "3. 'Marco's Pizza' (ID 19915) with similarity score: 0.2626\n"
     ]
    }
   ],
   "source": [
    "similarity_calculator1 = SimpleSimilarityCalculator(item_user_matrix_yelp, movie_title_dict_yelp)\n",
    "similarity_calculator1.print_top_k_similar_movies((6), k=70, display_count=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">6 Comparing Results</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section examines the outcomes derived from our Item-Based KNN model for Collaborative Filtering. We initiated our investigation using the Movielens dataset as a foundation. Initially, we established a predictive framework based on item similarity. We then used the KNN model to predict the ratings for the top k recommended movies. We then compared the predicted ratings with the actual ratings in the test set and evaluated the model's performance. The evaluation has been done using metrics such as RMSE (Root Mean Square Error) and MAE (Mean Absolute Error).\n",
    "\n",
    "\n",
    "Expanding our analysis to discover datasets from Movielens and Yelp, we maintained a consistent methodology. We used the same classes and functions to predict ratings and to find the best RMSE and MAE. However, for the Yelp dataset the recommender tool did not work properly so a basic similarity model was applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Movielens**:\n",
    "\n",
    "*`Best Parameter`*: Best Parameters: Metric=cosine, k=60\n",
    "\n",
    "Tuning:\n",
    "\n",
    "- Tuning RMSE: 1.2588\n",
    "- Tuning MAE: 0.9713\n",
    "\n",
    "Test: K=60\n",
    "\n",
    "- Test RMSE: 1.2414\n",
    "- Test MAE: 0.9574\n",
    "\n",
    "### **Netflix**:\n",
    "\n",
    "*`Best Parameter`*: Best Parameters: Metric=cosine, k=100\n",
    "\n",
    "Tuning:\n",
    "\n",
    "- Tuning RMSE: 1.1554\n",
    "- Tuning MAE: 0.8865\n",
    "\n",
    "Test:\n",
    "\n",
    "- Test RMSE: 1.7210\n",
    "- Test MAE: 1.2000\n",
    "\n",
    "### **Yelp**:\n",
    "\n",
    "*`Best Parameter`*: Best Parameters: Metric=cosine, k=3\n",
    "\n",
    "Tuning:\n",
    "\n",
    "- Tuning RMSE: 3.4445\n",
    "- Tuning MAE: 2.9967\n",
    "\n",
    "Test:\n",
    "\n",
    "- Test RMSE: 3.4745\n",
    "- Test MAE: 3.0635\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #FFA726; padding: 20px; color: #FFFFFF; font-family: 'Roboto', Helvetica, Arial, sans-serif;\">\n",
    "    <h2 style=\"font-weight: bold; font-size: 36px; margin: 0;\">7. Conclusion</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have explored the concept of Item-Based Collaborative Filtering. We implemented the algorithm from scratch, understood its underlying principles, and evaluated its performance. \n",
    "\n",
    "The results show that the algorithm is capable of making accurate recommendations based on item similarity. However, like any algorithm, it has its limitations and there is room for improvement. The results show that Movielens with (filtered data from 25 million for computational efficiency) 3 million data points has a higeher RMSE than Netflix with (filtered data from 80 million for computational efficiency) 8 million  data points. Indicating that the richer the data, the better the performance.\n",
    "\n",
    "Future work could involve exploring different similarity measures, incorporating more user data, or trying out different recommendation algorithms.\n",
    "\n",
    "Thank you for following along with this notebook. We hope it has been informative and helpful in understanding Item-Based Collaborative Filtering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
